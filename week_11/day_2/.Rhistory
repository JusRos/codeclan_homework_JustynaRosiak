knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
library(rpart)
library(rpart.plot)
library(tidyverse)
library(tidyverse)
titanic_set <- read_csv('data/titanic_decision_tree_data.csv')
shuffle_index <- sample(1:nrow(titanic_set))
# shuffle the data so class order isn't in order - need this for training/testing split later on
titanic_set <- titanic_set[shuffle_index, ]
titanic_clean <- titanic_set %>%
filter(survived %in% c(0,1)) %>%
# Convert to factor level
mutate(sex = as.factor(sex),
age_status = as.factor(if_else(age <= 16, "child", "adult")),
class = factor(pclass, levels = c(3,2,1), labels = c("Lower", "Middle", "Upper")),
survived_flag = factor(survived, levels = c(0,1), labels = c("Didn't survive", "Yes, survived")),
port_embarkation = as.factor(embarked)) %>%
select(sex, age_status, class, port_embarkation, sib_sp, parch, survived_flag) %>%
na.omit()
skimr::skim(titanic_clean)
head(titanic_clean)
library(GGally)
titanic_clean %>%
ggpairs(progress = FALSE)
# I have chosen 75/25 split as it offered a well balanced split across both data sets..
# how many rows in tol=tal
n_data <- nrow(titanic_clean)
# create a test sample index
test_index <- sample(1:n_data, size = n_data* 0.25)
titanic_test <- slice(titanic_clean, test_index)
titanic_train <- slice(titanic_clean, -test_index)
# check if the sets are balanced
titanic_test %>%
janitor::tabyl(survived_flag)
titanic_train %>%
janitor::tabyl(survived_flag)
# they seem to be balanced
# 1. make tree model
titanic_fit <- rpart(
formula = survived_flag ~ ., # include all variables
data = titanic_train,
method = "class" # 'class' for a categorical predictor
)
# plot the model
rpart.plot(titanic_fit,
yesno = 2, # this writes yes/no at all splits
type = 2, # dictates where our condition lie at each node
fallen.leaves = TRUE, # true means all leaves lie on the bottom
faclen = 6, # factor names length
digits = 2, # how many decimal places is probability reported to
split.border.col = 13, cex = 1 # colour of borders
)
library(modelr)
# add predictions
titanic_test_pred <- titanic_test %>%
add_predictions (titanic_fit, type = "class")
# look at predictions using the most useful variables
titanic_test_pred %>%
select(sex, class, sib_sp, age_status, survived_flag, pred)
# checking model performance
library(yardstick)
conf_mat <-titanic_test_pred %>% # confusion matrix
conf_mat(truth = survived_flag, estimate = pred)
conf_mat
# check for accuracy
accuracy <- titanic_test_pred %>%
accuracy(truth = survived_flag, estimate = pred)
accuracy
# check for sensitivity
sensitivity <- titanic_test_pred %>%
sensitivity(truth = survived_flag, estimate = pred)
sensitivity
