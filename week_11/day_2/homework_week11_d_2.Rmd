---
title: "Decision trees homework"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
```


<br>
In this homework we will create a decision tree to see which factors are useful in predicting whether or not a passenger on the titanic will survive.  


Run the code below before you begin: 


```{r, warning = FALSE, message = FALSE}
library(rpart)
library(rpart.plot)
library(tidyverse)

library(tidyverse)
titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

<br>

**Data Dictionary**

  * **sex**: Biological Sex, male or female  
  * **age_status**: adult or child (child defined as under 16)  
  * **class** : Ticket class, 1 = 1st (Upper class), 2 = 2nd (Middle Class), 3 = 3rd (Lower Class)    
  * **port_embarkation**: C = Cherbourg, Q = Queenstown, S = Southampton  
  * **sibsp** : number of siblings / spouses aboard the Titanic   
  * **parch**: number of parents / children aboard the Titanic. Some children travelled only with a nanny, therefore parch=0 for them. 
  * **survived_flag** : did they survive, 0 = No, 1 = Yes  



# MVP 


## Question 1  

<br> 
Cleaning up the data is always the first step. Do the following: 

  * Take only observations which have a `survived` flag (i.e. that aren't missing)  
  * Turn your important variables into factors (sex, survived, pclass, embarkation)  
  * Create an `age_status` variable which groups individuals under (and including) 16 years of age into a category called "child" category and those over 16 into a category called "adult".  
  * Drop the NA  
  * Drop any variables you don't need (`X1`, `passenger_id`, `name`, `ticket`, `far`, `cabin`)  

If you need help doing this, the code is below, but please try it yourself first so you can learn!

<br>
<details>
<summary>**Data Cleaning Code** </summary>
<br>

```{r}
titanic_clean <- titanic_set %>%
  filter(survived %in% c(0,1)) %>%
# Convert to factor level
	mutate(sex = as.factor(sex), 
	       age_status = as.factor(if_else(age <= 16, "child", "adult")),
         class = factor(pclass, levels = c(3,2,1), labels = c("Lower", "Middle", "Upper")), 
	       survived_flag = factor(survived, levels = c(0,1), labels = c("Didn't survive", "Yes, survived")), 
	       port_embarkation = as.factor(embarked)) %>%
  select(sex, age_status, class, port_embarkation, sib_sp, parch, survived_flag) %>%
  na.omit()
```
</details>


<br>

## Question 2  

<br> 
Have a look at your data and create some plots to ensure you know what you're working with before you begin. Write a summary of what you have found in your plots. Which variables do you think might be useful to predict whether or not people are going to die? Knowing this before you start is the best way to have a sanity check that your model is doing a good job.  


```{r}
skimr::skim(titanic_clean)

head(titanic_clean)


```


```{r}

library(GGally)
titanic_clean %>% 
ggpairs(progress = FALSE)
```
It looks like males were more likely to die than females and people classified as adults. People in lower class were more likely to die and people in the upper class least likely to die.It doesn't look that having a sibling or spouse made a difference.
It looks like there was more males on titanic and more adults than children. Most people boarded titanic in S = Southampton and there was more people travelling in third class. 

<br>

## Question 3  

<br> 
Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced. [**Extra** - if you want to force balanced testing and training sets, have a look at the `stratified()` function in package `splitstackshape` (you can specify multiple variables to stratify on by passing a vector of variable names to the `group` argument, and get back testing and training sets with argument `bothSets = TRUE`)]


```{r}

# I have chosen 75/25 split as it offered a well balanced split across both data sets..
# how many rows in tol=tal 
n_data <- nrow(titanic_clean)

# create a test sample index

test_index <- sample(1:n_data, size = n_data* 0.25)


titanic_test <- slice(titanic_clean, test_index)
titanic_train <- slice(titanic_clean, -test_index)


# check if the sets are balanced 
titanic_test %>% 
  janitor::tabyl(survived_flag)

titanic_train %>% 
  janitor::tabyl(survived_flag)

# they seem to be balanced
```



## Question 4      

<br> 
Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot.

```{r}
# 1. make tree model

titanic_fit <- rpart(
  formula = survived_flag ~ ., # include all variables 
  data = titanic_train,
  method = "class" # 'class' for a categorical predictor
  
)

# plot the model

rpart.plot(titanic_fit, 
           yesno = 2, # this writes yes/no at all splits
           type = 2, # dictates where our condition lie at each node
           fallen.leaves = TRUE, # true means all leaves lie on the bottom
           faclen = 6, # factor names length 
           digits = 2, # how many decimal places is probability reported to
           split.border.col = 13, cex = 1 # colour of borders
)
```


## Question 5    

<br> 
Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.    
The probability of surviving while on titanic is 0.41.
It looks like gender is the biggest predictor here - especially being a male, as 63 percent of all people who died were males. Being a female who marveled in the upper and middle class increased the probability of surviving to 0.94. Being a female under age of 16 also meant a high chance of surviving - 0.72. 22% of all records from the data set have fallen in to the category of being a female who traveled in the middle and upper class.Those who traveled with less than 3 family members ( spouses or siblings) had a greater chance of surviving if they were a child and female. 25% of all teh category from teh data set had fallen into a survived category.

<br>

## Question 6     

<br>  
Test and add your predictions to your data. Create a confusion matrix. Write down in detail what this tells you for this specific dataset. 

```{r}

library(modelr)

# add predictions

titanic_test_pred <- titanic_test %>% 
  add_predictions (titanic_fit, type = "class")

# look at predictions using the most useful variables
titanic_test_pred %>% 
  select(sex, class, sib_sp, age_status, survived_flag, pred)


# checking model performance 

library(yardstick)

conf_mat <-titanic_test_pred %>% # confusion matrix
  conf_mat(truth = survived_flag, estimate = pred)

conf_mat

```

148(105 + 43) were predicted correctly

```{r}
# check for accuracy 

accuracy <- titanic_test_pred %>% 
  accuracy(truth = survived_flag, estimate = pred)

accuracy
```
```{r}
# check for sensitivity

sensitivity <- titanic_test_pred %>% 
  sensitivity(truth = survived_flag, estimate = pred)

sensitivity
```
Sensitivity is very high which means that model is identifying 97% of the positive cases in the data set (identifies 97% of caases of those who survived), while it incorrectly classifies 3% of the positive instances as negative ( False negatives - it says they survived while they didn't survive).

```{r}
# check for specificity
specificity <- titanic_test_pred %>% 
  specificity(truth = survived_flag, estimate = pred)

specificity
```
Specificity at 61% means that the model predicts all the negatives( didn't survive) correctly at that level, however it also classifies 39% of teh negative instances as positive( false)

# Extension  

See how a `ranger()` random forest classifier compares with a single decision tree in terms of performance. Can you tune the values of the `mtry`, `splitrule` and `min.node.size` hyperparameters? Which variables in the dataset turn out to be most important for your best model? The `Kappa` metric might be the best one to focus on if you want to improve performance for an imbalanced data set. Do some research on the definition of `Kappa` before you start.

We provide the code in the dropdown below if you get stuck, but still want to play around with this (note that run time can be up to 5-10 mins for the tuning). **Save your notebook before you begin** in case you need to force quit your session!

<br>
<details>
<summary>**Code**</summary>

```{r, eval=FALSE}
library(ranger)

control <- trainControl(
  method = "repeatedcv", 
  number = 5, 
  repeats = 10
)

tune_grid = expand.grid(
  mtry = 1:6,
  splitrule = c("gini", "extratrees"),
  min.node.size = c(1, 3, 5)
)
```
014
```{r, eval=FALSE}
rf_tune <- train(
  survived_flag ~ ., 
  data = titanic_train, 
  method = "ranger",
  metric = "Kappa",
  num.trees = 1000,
  importance = "impurity",
  tuneGrid = tune_grid, 
  trControl = control
)

plot(rf_tune)
rf_tune
```
</details>
<br>

